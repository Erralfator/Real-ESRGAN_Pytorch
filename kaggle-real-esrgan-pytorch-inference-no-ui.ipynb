{"metadata":{"colab":{"provenance":[],"collapsed_sections":["6BPxh_VmVVIu"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Real-ESRGAN Pytorch Inference NO UI\n\n[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2107.10833)\n[![GitHub Stars](https://img.shields.io/github/stars/Nick088Official/Real-ESRGAN_Pytorch?style=social)](https://github.com/Nick088Official/Real-ESRGAN_Pytorch)\n\nThis is a **Practical Image Restoration Demo** of the Pytorch ai-forever custom pretrained Real-ESRGAN models.\nWe extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data. <br>\nThe following figure shows some real-life examples.\n\nLow quality image:\n\n![](https://github.com/Nick088Official/Real-ESRGAN-Pytorch/blob/main/inputs/lr_lion.png?raw=1)\n\nReal-ESRGAN_Pytorch result:\n\n![](https://github.com/Nick088Official/Real-ESRGAN-Pytorch/blob/main/results/sr_lion.png?raw=1)\n\n**Note that Real-ESRGAN may still fail in some cases as the real-world degradations are really too complex.**<br>\nMoreover, it **may not** perform well on **human faces, you could try [GFPGAN](https://colab.research.google.com/github/Nick088Official/GFPGAN-Fix/blob/master/GFPGAN_fix_inference.ipynb) for that\n<br>\n\nThis is the Pytorch Implementation of https://github.com/ai-forever/Real-ESRGAN\n\n**Credits:** [Nick088](https://linktr.ee/Nick088), Xinntao, Tencent, Geeve George, ai-forever","metadata":{"id":"IRDbDYYMQt_Y"}},{"cell_type":"code","source":"# Installation\n\n# By running this, we clone the repository, set up the envrironment.\nfrom IPython.display import clear_output\nimport torch\n\nif torch.cuda.is_available():\n    device = \"cuda\"\n    print(\"Using GPU\")\nelse:\n    device = \"cpu\"\n    print(\"Using CPU\")\n\n!git clone https://github.com/Nick088Official/Real-ESRGAN_Pytorch/\n%cd Real-ESRGAN_Pytorch/Scripts\n!pip install -r requirements_no_ui.txt\n!pip install gdown\nfrom RealESRGAN import RealESRGAN\nfrom PIL import Image\nimport numpy as np\nimport ffmpeg\n%cd ..\nclear_output()\nprint(f'Installed on {\"GPU\" if torch.cuda.is_available() else \"CPU\"}!')","metadata":{"id":"GnpnrLfMV2jU","cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download & Upload Input from Google Drive\n\nimport gdown \n\ngoogle_drive_url = \"\" # change the link to the input file you uploaded in google drive \ndownload_name = \"Target.mp4\" # name the input whatever you want\n\ndef extract_drive_id(google_drive_url):\n    try:\n        # Split the URL by '/'\n        parts = google_drive_url.split('/')\n        # Get the part containing the file ID\n        file_id_part = parts[-2]\n        # Split the file ID part by '='\n        file_id = file_id_part.split('=')[-1]\n        return file_id\n    except IndexError:\n        return None\n\n\n# Define the folders\nupload_folder = 'inputs'\nresult_folder = 'results'    \n    \n    \n# Example usage\nfile_id = extract_drive_id(google_drive_url)\nif file_id:\n    %cd inputs\n    !gdown -O $download_name $file_id\n    print(\"Downloaded Input from Google Drive to inputs folder!\")\n    %cd ..\nelse:\n    print(\"Invalid Google Drive URL.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inference Input Image/Video\n\nfilename_input = 'Target.mp4' # Put the name of the downloaded input in the inputs folder from google drive\n\nmodel_scale = \"2\" # Choose \"2\", \"4\" or \"8\"\n\ninfer_no_ui_command = f\"Scripts/Infer_NO_UI.py --file '{filename_input}' --size {model_scale}\"\n\n!python $infer_no_ui_command","metadata":{"id":"TOrRoYCA9tUh","cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize Input vs Output Image (Image Input ONLY)\n\n# utils for visualization\nimport cv2\nimport matplotlib.pyplot as plt\ndef display(img1, img2):\n  fig = plt.figure(figsize=(25, 10))\n  ax1 = fig.add_subplot(1, 2, 1)\n  plt.title('Input image', fontsize=16)\n  ax1.axis('off')\n  ax2 = fig.add_subplot(1, 2, 2)\n  plt.title(f'Real-ESRGAN Pytorch x{model_scale} output', fontsize=16)\n  ax2.axis('off')\n  ax1.imshow(img1)\n  ax2.imshow(img2)\ndef imread(img_path):\n  img = cv2.imread(img_path)\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  return img\n\n# display each image in the upload folder\nimport os\nimport glob\n\ninput_folder = 'inputs'\nresult_folder = 'results'\ninput_list = sorted(glob.glob(os.path.join(input_folder, '*')))\noutput_list = sorted(glob.glob(os.path.join(result_folder, '*')))\nfor input_path, output_path in zip(input_list, output_list):\n  img_input = imread(input_path)\n  img_output = imread(output_path)\n  display(img_input, img_output)","metadata":{"id":"7IMD5vhOYp68","cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HOW TO DOWNLOAD OUTPUT SKIN (ASSET & 3D MODEL)\nAt your right you should find 'Output', expand the /kaggle/working folder and then the Real-ESRGAN_Pytorch folder, you will find the upscaled output image/video in the 'results' folder with the name of the input that you gave it before when downloading from google drive, just click the 3 dots at its right of it and click download","metadata":{}},{"cell_type":"code","source":"# Delete Inputs & Outputs\n# You need to run this to clear the previous inputs and ouputs after you finished inferencing the images you wanted and downloaded the results, only after this you can inference again.\n\nshutil.rmtree(upload_folder)\nshutil.rmtree(result_folder)\nos.makedirs(upload_folder, exist_ok=True)\nos.makedirs(result_folder, exist_ok=True)\nprint(\"Deleted previous Inputs & Outputs Images, now you can inference again.\")","metadata":{"cellView":"form","id":"qOEvBZYACZIO"},"execution_count":null,"outputs":[]}]}