{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6BPxh_VmVVIu"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/Real-ESRGAN_Pytorch/blob/main/Real_ESRGAN_Pytorch_Inference_NO_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRDbDYYMQt_Y"
      },
      "source": [
        "# Real-ESRGAN Pytorch Inference NO UI\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2107.10833)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/Nick088Official/Real-ESRGAN_Pytorch?style=social)](https://github.com/Nick088Official/Real-ESRGAN_Pytorch)\n",
        "\n",
        "This is a **Practical Image Restoration Demo** of the Pytorch ai-forever custom pretrained Real-ESRGAN models.\n",
        "We extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data. <br>\n",
        "The following figure shows some real-life examples.\n",
        "\n",
        "Low quality image:\n",
        "\n",
        "![](https://github.com/Nick088Official/Real-ESRGAN-Pytorch/blob/main/inputs/lr_lion.png?raw=1)\n",
        "\n",
        "Real-ESRGAN_Pytorch result:\n",
        "\n",
        "![](https://github.com/Nick088Official/Real-ESRGAN-Pytorch/blob/main/results/sr_lion.png?raw=1)\n",
        "\n",
        "**Note that Real-ESRGAN may still fail in some cases as the real-world degradations are really too complex.**<br>\n",
        "Moreover, it **may not** perform well on **human faces, you could try [GFPGAN](https://colab.research.google.com/github/Nick088Official/GFPGAN-Fix/blob/master/GFPGAN_fix_inference.ipynb) for that\n",
        "<br>\n",
        "\n",
        "This is the Pytorch Implementation of https://github.com/ai-forever/Real-ESRGAN\n",
        "\n",
        "**Credits:** [Nick088](https://linktr.ee/Nick088), Xinntao, Tencent, Geeve George, ai-forever"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnpnrLfMV2jU",
        "cellView": "form"
      },
      "source": [
        "#@title Installation\n",
        "#@markdown Before running, make sure that you choose\n",
        "#@markdown * Runtime Type = Python 3\n",
        "#@markdown * Hardware Accelerator = GPU (Faster, free daily limit of gpu around 12 hours) or CPU (very slow)\n",
        "\n",
        "#@markdown in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "#@markdown By running this, we clone the repository, set up the envrironment.\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "!pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git\n",
        "%cd Real-ESRGAN\n",
        "!pip install ffmpeg-python\n",
        "from RealESRGAN import RealESRGAN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import ffmpeg\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model2 = RealESRGAN(device, scale=2)\n",
        "model2.load_weights('weights/RealESRGAN_x2.pth', download=True)\n",
        "model4 = RealESRGAN(device, scale=4)\n",
        "model4.load_weights('weights/RealESRGAN_x4.pth', download=True)\n",
        "model8 = RealESRGAN(device, scale=8)\n",
        "model8.load_weights('weights/RealESRGAN_x8.pth', download=True)\n",
        "clear_output()\n",
        "print(f'Installed with all its models on {\"GPU\" if torch.cuda.is_available() else \"CPU\"}!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Images"
      ],
      "metadata": {
        "id": "t29jRWtY33fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload & Inference Images\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from io import BytesIO\n",
        "import io\n",
        "\n",
        "\n",
        "model_scale = \"4\" #@param [\"2\", \"4\", \"8\"] {allow-input: false}\n",
        "\n",
        "model = RealESRGAN(device, scale=int(model_scale))\n",
        "model.load_weights(f'weights/RealESRGAN_x{model_scale}.pth', download=False)\n",
        "\n",
        "\n",
        "upload_folder = 'inputs'\n",
        "result_folder = 'results'\n",
        "\n",
        "os.makedirs(upload_folder, exist_ok=True)\n",
        "os.makedirs(result_folder, exist_ok=True)\n",
        "\n",
        "IMAGE_FORMATS = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
        "\n",
        "\n",
        "def process_input(filename):\n",
        "  result_image_path = os.path.join('results/', os.path.basename(filename))\n",
        "  image = Image.open(filename).convert('RGB')\n",
        "  sr_image = model.predict(np.array(image))\n",
        "  sr_image.save(result_image_path)\n",
        "  print(f'Finished! Image saved to {result_image_path}')\n",
        "\n",
        "# upload files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(upload_folder, filename)\n",
        "    shutil.move(filename, dst_path)\n",
        "    print(f'moved input {filename} to {dst_path}')\n",
        "    print('Processing:', filename)\n",
        "    process_input(f\"inputs/{filename}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IGhqWuHxyLc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IMD5vhOYp68",
        "cellView": "form"
      },
      "source": [
        "#@title Visualize Input vs Output Image\n",
        "# utils for visualization\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title(f'Real-ESRGAN Pytorch x{model_scale} output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs'\n",
        "result_folder = 'results'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNHoP8PZJQ7",
        "cellView": "form"
      },
      "source": [
        "#@title Download the results\n",
        "zip_filename = f'Real-ESRGAN-Pytorch-x{model_scale}_result.zip'\n",
        "if os.path.exists(zip_filename):\n",
        "  os.remove(zip_filename)\n",
        "os.system(f\"zip -r -j {zip_filename} results/*\")\n",
        "files.download(zip_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete Inputs & Outputs Image\n",
        "#@markdown You need to run this to clear the previous inputs and ouputs after you finished inferencing the images you wanted and downloaded the results, only after this you can inference again.\n",
        "\n",
        "shutil.rmtree(upload_folder)\n",
        "shutil.rmtree(result_folder)\n",
        "print(\"Deleted previous Inputs & Outputs Images, now you can inference again.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qOEvBZYACZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Videos"
      ],
      "metadata": {
        "id": "9SKvWeXt36Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Input Video\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "video_folder = 'videos'\n",
        "video_result_folder = 'results_videos'\n",
        "video_mp4_result_folder = 'results_mp4_videos'\n",
        "result_restored_imgs_folder = 'restored_imgs'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "  print(upload_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "if os.path.isdir(video_folder):\n",
        "  print(video_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_folder)\n",
        "\n",
        "if os.path.isdir(video_result_folder):\n",
        "  print(video_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_result_folder)\n",
        "\n",
        "if os.path.isdir(video_mp4_result_folder):\n",
        "  print(video_mp4_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_mp4_result_folder)\n",
        "\n",
        "if os.path.isdir(result_folder):\n",
        "  print(result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(result_folder)\n",
        "\n",
        "%cd results\n",
        "if os.path.isdir(result_restored_imgs_folder):\n",
        "  print(result_restored_imgs_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(result_restored_imgs_folder)\n",
        "%cd ..\n",
        "\n",
        "if os.path.isdir(video_folder):\n",
        "    shutil.rmtree(video_folder)\n",
        "os.mkdir(video_folder)\n",
        "\n",
        "%cd videos\n",
        "# upload images\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(video_folder, filename)\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  name_video_file_input = f'/content/videos/{filename}'\n",
        "  print(f'moved {filename} of {fps} fps to {dst_path}')\n",
        "%cd .."
      ],
      "metadata": {
        "cellView": "form",
        "id": "45Z6XKp5jXDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference Videos\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from io import BytesIO\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "IMAGE_FORMATS = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
        "\n",
        "model_scale = \"2\" #@param [\"2\", \"4\", \"8\"] {allow-input: false}\n",
        "\n",
        "model = RealESRGAN(device, scale=int(model_scale))\n",
        "model.load_weights(f'weights/RealESRGAN_x{model_scale}.pth', download=False)\n",
        "\n",
        "def process_input(filename):\n",
        "  result_image_path = os.path.join('results/restored_imgs', os.path.basename(filename))\n",
        "  image = Image.open(filename).convert('RGB')\n",
        "  sr_image = model.predict(np.array(image))\n",
        "  sr_image.save(result_image_path)\n",
        "  print(f'Finished Frame of the Video, saved to {result_image_path}!')\n",
        "\n",
        "# assign directory\n",
        "directory = 'videos' #PATH_WITH_INPUT_VIDEOS\n",
        "zee = 0\n",
        "\n",
        "def convert_frames_to_video(pathIn,pathOut,fps):\n",
        "    frame_array = []\n",
        "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "    #for sorting the file names properly\n",
        "    files.sort(key = lambda x: int(x[5:-4]))\n",
        "    size2 = (0,0)\n",
        "\n",
        "    for i in range(len(files)):\n",
        "        filename=pathIn + files[i]\n",
        "        #reading each files\n",
        "        img = cv2.imread(filename)\n",
        "        height, width, layers = img.shape\n",
        "        size = (width,height)\n",
        "        size2 = size\n",
        "        print(filename)\n",
        "        #inserting the frames into an image array\n",
        "        frame_array.append(img)\n",
        "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size2)\n",
        "    for i in range(len(frame_array)):\n",
        "        # writing to a image array\n",
        "        out.write(frame_array[i])\n",
        "    out.release()\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        print(\"PROCESSING :\"+str(f)+\"\\n\")\n",
        "        # Read the video from specified path\n",
        "\n",
        "        # Check if the input video has an audio stream\n",
        "        probe = ffmpeg.probe(f)\n",
        "        has_audio = any(stream['codec_type'] == 'audio' for stream in probe['streams'])\n",
        "\n",
        "        if has_audio:\n",
        "            # Extract audio from the input video\n",
        "            audio_file = f.replace(\".mp4\", \".wav\")\n",
        "            ffmpeg.input(f).output(audio_file, format='wav', ac=1).run(overwrite_output=True)\n",
        "\n",
        "        # video to frames\n",
        "        cam = cv2.VideoCapture(str(f))\n",
        "\n",
        "        try:\n",
        "            # PATH TO STORE VIDEO FRAMES\n",
        "            if not os.path.exists('upload'):\n",
        "                os.makedirs('upload')\n",
        "\n",
        "        # if not created then raise error\n",
        "        except OSError:\n",
        "            print ('Error: Creating directory of data')\n",
        "\n",
        "        # frame\n",
        "        currentframe = 0\n",
        "\n",
        "        while(True):\n",
        "            # reading from frame\n",
        "            ret,frame = cam.read()\n",
        "\n",
        "            if ret:\n",
        "                # if video is still left continue creating images\n",
        "                name = 'upload/frame' + str(currentframe) + '.jpg'\n",
        "\n",
        "                # writing the extracted images\n",
        "                cv2.imwrite(name, frame)\n",
        "\n",
        "                # increasing counter so that it will\n",
        "                # show how many frames are created\n",
        "                currentframe += 1\n",
        "                print(currentframe)\n",
        "            else:\n",
        "                #deletes all the videos you uploaded for upscaling\n",
        "                #for f in os.listdir(video_folder):\n",
        "                #  os.remove(os.path.join(video_folder, f))\n",
        "\n",
        "                break\n",
        "\n",
        "        # Release all space and windows once done\n",
        "        cam.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        #apply super-resolution on all frames of a video\n",
        "\n",
        "        # Specify the directory path\n",
        "        all_frames_path = \"upload\"\n",
        "\n",
        "        # Get a list of all files in the directory\n",
        "        file_names = os.listdir(all_frames_path)\n",
        "\n",
        "        # process the files\n",
        "        for file_name in file_names:\n",
        "            process_input(f\"upload/{file_name}\")\n",
        "\n",
        "        #convert super res frames to .avi\n",
        "        pathIn = 'results/restored_imgs/'\n",
        "\n",
        "        zee = zee+1\n",
        "        fName = \"video\"+str(zee)\n",
        "        filenameVid = f\"{fName}.avi\"\n",
        "\n",
        "        pathOut = \"results_videos/\"+filenameVid\n",
        "\n",
        "        convert_frames_to_video(pathIn, pathOut, fps)\n",
        "\n",
        "        # Re-encode the video with the modified audio\n",
        "        ffmpeg.input(pathOut).output(pathOut.replace(\".avi\", \".mp4\"), vcodec='libx264', acodec='aac', audio_bitrate='320k').run(overwrite_output=True)\n",
        "\n",
        "        if has_audio:\n",
        "            # Replace the original audio with the upscaled audio\n",
        "            ffmpeg.input(audio_file).output(pathOut.replace(\".avi\", \".mp4\"), acodec='aac', audio_bitrate='320k').run(overwrite_output=True)\n",
        "\n",
        "        #convert .avi to .mp4\n",
        "        src = 'results_videos/'\n",
        "        dst = 'results_mp4_videos/'\n",
        "\n",
        "        for root, dirs, filenames in os.walk(src, topdown=False):\n",
        "            #print(filenames)\n",
        "            for filename in filenames:\n",
        "                print('[INFO] 1',filename)\n",
        "                try:\n",
        "                    _format = ''\n",
        "                    if \".flv\" in filename.lower():\n",
        "                        _format=\".flv\"\n",
        "                    if \".mp4\" in filename.lower():\n",
        "                        _format=\".mp4\"\n",
        "                    if \".avi\" in filename.lower():\n",
        "                        _format=\".avi\"\n",
        "                    if \".mov\" in filename.lower():\n",
        "                        _format=\".mov\"\n",
        "\n",
        "                    inputfile = os.path.join(root, filename)\n",
        "                    print('[INFO] 1',inputfile)\n",
        "                    outputfile = os.path.join(dst, filename.lower().replace(_format, \".mp4\"))\n",
        "                    subprocess.call(['ffmpeg', '-i', inputfile, outputfile])\n",
        "                    name_video_file_output = f'/content/{outputfile}'\n",
        "                    clear_output()\n",
        "                    print(\"Successfully processed the video!\")\n",
        "                except:\n",
        "                    print(\"An exception occurred\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VE8gV51NoZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Input vs Output Video\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Read the input video file\n",
        "mp4_input = open(f'{name_video_file_input}', 'rb').read()\n",
        "\n",
        "# Read the output video file (modify this path accordingly)\n",
        "mp4_output = open(f'{name_video_file_output}', 'rb').read()\n",
        "\n",
        "# Create data URLs for both videos\n",
        "data_url_input = \"data:video/mp4;base64,\" + b64encode(mp4_input).decode()\n",
        "data_url_output = \"data:video/mp4;base64,\" + b64encode(mp4_output).decode()\n",
        "\n",
        "# Display the videos side by side\n",
        "HTML(f\"\"\"\n",
        "<div style=\"display: flex; align-items: center; justify-content: center;\">\n",
        "    <div style=\"text-align: center;\">\n",
        "        <h2>Input</h2>\n",
        "        <video width=400 controls>\n",
        "            <source src='{data_url_input}' type='video/mp4'>\n",
        "        </video>\n",
        "    </div>\n",
        "    <div style=\"font-size: 24px; margin: 0 20px;\">vs</div>\n",
        "    <div style=\"text-align: center;\">\n",
        "        <h2>Output</h2>\n",
        "        <video width=400 controls>\n",
        "            <source src='{data_url_output}' type='video/mp4'>\n",
        "        </video>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S805GtjhKDVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1CLOX-ICT0",
        "cellView": "form"
      },
      "source": [
        "#@title Download Video & Frames Results\n",
        "#@markdown It will download you a .zip, unzip it however you want\n",
        "\n",
        "#@markdown It will have 2 folders:\n",
        "\n",
        "#@markdown 1. 'results' , which has inside 'restored_imgs' = the results of the frames of the video\n",
        "\n",
        "#@markdown 2. 'results_mp4_videos' = the results of the video after the face has been restored (so basically all the frames together)\n",
        "\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system(f'zip -r download.zip results/restored_imgs results_mp4_videos')\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete Inputs & Outputs Videos\n",
        "#@markdown You need to run this to clear the previous inputs and ouputs after you finished inferencing the videos you wanted and downloaded the results, only after this you can inference again.\n",
        "\n",
        "shutil.rmtree(upload_folder)\n",
        "shutil.rmtree(result_folder)\n",
        "shutil.rmtree(video_folder)\n",
        "shutil.rmtree(video_result_folder)\n",
        "shutil.rmtree(video_mp4_result_folder)\n",
        "\n",
        "print(\"Deleted previous Inputs & Outputs Videos, now you can inference again.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b9575v83tCw7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}